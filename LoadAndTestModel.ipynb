{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "from time import time\n",
    "import io\n",
    "import re\n",
    "\n",
    "import pickle\n",
    "from csv import reader\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors\n",
    "from matplotlib.ticker import PercentFormatter\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.backend import sparse_categorical_crossentropy\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "# physical_devices = tf.config.list_physical_devices('GPU') \n",
    "# tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "\n",
    "from datetime import datetime\n",
    "from collections import defaultdict\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'),\n",
       " PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TFXLNetForSequenceClassification, XLNetTokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_section = pd.read_table(\"Article-Bias-Prediction-main/data/randomtraindata.csv\", sep=',', index_col=0)\n",
    "test_section = pd.read_table(\"Article-Bias-Prediction-main/data/randomtestdata.csv\", sep=',', index_col=0)\n",
    "val_section = pd.read_table(\"Article-Bias-Prediction-main/data/randomtestdata.csv\", sep=',', index_col=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_section = train_section[:20000]\n",
    "val_section = train_section[:4000]\n",
    "\n",
    "\n",
    "\n",
    "# test_section = pd.read_table(\"Article-Bias-Prediction-main/data/randomtestdata.csv\", sep=',', index_col=0)\n",
    "# val_section = pd.read_table(\"Article-Bias-Prediction-main/data/randomtestdata.csv\", sep=',', index_col=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "train_section[\"bias_text\"].value_counts().plot(ax=ax, kind=\"bar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "val_section[\"bias_text\"].value_counts().plot(ax=ax, kind=\"bar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "test_section[\"bias_text\"].value_counts().plot(ax=ax, kind=\"bar\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN = 512\n",
    "nepochs = 50\n",
    "nbatch = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"./data\"\n",
    "log_dir = f\"{data_dir}/experiments/logs\"\n",
    "save_path = f\"{data_dir}/experiments/XLNetmodel1\"\n",
    "cache_path_train = f\"{data_dir}/cache/XLNetmodel1.train\"\n",
    "cache_path_test = f\"{data_dir}/cache/XLNetmodel1.test\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transforming Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "train_labels = np.asarray(le.fit_transform(train_section['bias_text']))\n",
    "val_labels = np.asarray(le.transform(val_section['bias_text']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# le.inverse_transform(val_labels)[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(np.unique(train_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_transformer = XLNetTokenizer.from_pretrained('xlnet-large-cased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_input_array(df, tokenizer):\n",
    "    sentences = df.content.values\n",
    "\n",
    "    input_ids = []\n",
    "    attention_masks = []\n",
    "    token_type_ids = []\n",
    "\n",
    "    for sent in sentences:\n",
    "        # `encode_plus` will:\n",
    "        #   (1) Tokenize the sentence.\n",
    "        #   (2) Prepend the `[CLS]` token to the start.\n",
    "        #   (3) Append the `[SEP]` token to the end.\n",
    "        #   (4) Map tokens to their IDs.\n",
    "        #   (5) Pad or truncate the sentence to `max_length`\n",
    "        #   (6) Create attention masks for [PAD] tokens.\n",
    "        encoded_dict = tokenizer.encode_plus(\n",
    "            sent,  # Sentence to encode.\n",
    "            add_special_tokens=True,  # Add '[CLS]' and '[SEP]'\n",
    "            max_length=MAX_LEN,  # Pad & truncate all sentences.\n",
    "                pad_to_max_length=True,\n",
    "                return_attention_mask=True,  # Construct attn. masks.\n",
    "                return_tensors='tf',  # Return tf tensors.\n",
    "            )\n",
    "\n",
    "        # Add the encoded sentence to the list.\n",
    "        input_ids.append(encoded_dict['input_ids'])\n",
    "\n",
    "        # And its attention mask (simply differentiates padding from non-padding).\n",
    "        attention_masks.append(encoded_dict['attention_mask'])\n",
    "\n",
    "        token_type_ids.append(encoded_dict['token_type_ids'])\n",
    "\n",
    "    input_ids = tf.convert_to_tensor(input_ids)\n",
    "    attention_masks = tf.convert_to_tensor(attention_masks)\n",
    "    token_type_ids = tf.convert_to_tensor(token_type_ids)\n",
    "\n",
    "\n",
    "    return input_ids, attention_masks, token_type_ids\n",
    "#     return input_ids, attention_masks\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:2104: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# train_inputs = [create_input_array(train_section, tokenizer=tokenizer_transformer)]\n",
    "# val_inputs = [create_input_array(val_section, tokenizer=tokenizer_transformer)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_inputs_to_tf_dataset(inputs):\n",
    "    # args.max_seq_len = 256\n",
    "    ids = inputs[0][0]\n",
    "    masks = inputs[0][1]\n",
    "    token_types = inputs[0][2]\n",
    "\n",
    "    ids = tf.reshape(ids, (-1, MAX_LEN))\n",
    "    print(\"Input ids shape: \", ids.shape)\n",
    "    masks = tf.reshape(masks, (-1, MAX_LEN))\n",
    "    print(\"Input Masks shape: \", masks.shape)\n",
    "    token_types = tf.reshape(token_types, (-1, MAX_LEN))\n",
    "    print(\"Token type ids shape: \", token_types.shape)\n",
    "\n",
    "    ids=ids.numpy()\n",
    "    masks = masks.numpy()\n",
    "    token_types = token_types.numpy()\n",
    "#     return[ids]\n",
    "#     return [ids, masks, token_types]\n",
    "    return [ids, masks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input ids shape:  (200, 512)\n",
      "Input Masks shape:  (200, 512)\n",
      "Token type ids shape:  (200, 512)\n",
      "Input ids shape:  (40, 512)\n",
      "Input Masks shape:  (40, 512)\n",
      "Token type ids shape:  (40, 512)\n"
     ]
    }
   ],
   "source": [
    "# train_data = convert_inputs_to_tf_dataset(train_inputs)\n",
    "# val_data = convert_inputs_to_tf_dataset(val_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1300, 12)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_section = pd.read_table(\"Article-Bias-Prediction-main/data/randomtestdata.csv\", sep=',', index_col=0)\n",
    "test_section.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input ids shape:  (1300, 512)\n",
      "Input Masks shape:  (1300, 512)\n",
      "Token type ids shape:  (1300, 512)\n"
     ]
    }
   ],
   "source": [
    "test_labels = np.asarray(le.transform(test_section['bias_text']))\n",
    "test_inputs = [create_input_array(test_section, tokenizer=tokenizer_transformer)]\n",
    "test_data = convert_inputs_to_tf_dataset(test_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Evaluate on test data\")\n",
    "results = model.evaluate(test_data, test_labels, batch_size=5)\n",
    "print(\"test loss, test acc:\", results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFXLNetForSequenceClassification.\n",
      "\n",
      "All the layers of TFXLNetForSequenceClassification were initialized from the model checkpoint at data/experiments/XLNetmodel1.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFXLNetForSequenceClassification for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "testmodel = TFXLNetForSequenceClassification.from_pretrained(\"data/experiments/XLNetmodel1\", num_labels=len(np.unique(train_labels)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "metric = tf.keras.metrics.SparseCategoricalAccuracy('accuracy')\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=2e-07, epsilon=1e-08)\n",
    "\n",
    "testmodel.compile(optimizer=optimizer, loss=loss, metrics=[metric])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testmodel.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": " OOM when allocating tensor with shape[512,1024,1,16] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node tfxl_net_for_sequence_classification/transformer/layer_._0/rel_attn/einsum_5/Einsum (defined at /usr/local/lib/python3.8/dist-packages/transformers/models/xlnet/modeling_tf_xlnet.py:140) ]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n [Op:__inference_predict_function_60897]\n\nErrors may have originated from an input operation.\nInput Source operations connected to node tfxl_net_for_sequence_classification/transformer/layer_._0/rel_attn/einsum_5/Einsum:\n tfxl_net_for_sequence_classification/transformer/layer_._0/rel_attn/einsum_3/Einsum (defined at /usr/local/lib/python3.8/dist-packages/transformers/models/xlnet/modeling_tf_xlnet.py:301)\n\nFunction call stack:\npredict_function\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-1d55ac1df2f5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# predict probabilities for test set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtest_probs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1627\u001b[0m           \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1628\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_predict_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1629\u001b[0;31m             \u001b[0mtmp_batch_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1630\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1631\u001b[0m               \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    860\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 862\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    863\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    864\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2940\u001b[0m       (graph_function,\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2942\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   2943\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1916\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1918\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1919\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    553\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 555\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    556\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    557\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m:  OOM when allocating tensor with shape[512,1024,1,16] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node tfxl_net_for_sequence_classification/transformer/layer_._0/rel_attn/einsum_5/Einsum (defined at /usr/local/lib/python3.8/dist-packages/transformers/models/xlnet/modeling_tf_xlnet.py:140) ]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n [Op:__inference_predict_function_60897]\n\nErrors may have originated from an input operation.\nInput Source operations connected to node tfxl_net_for_sequence_classification/transformer/layer_._0/rel_attn/einsum_5/Einsum:\n tfxl_net_for_sequence_classification/transformer/layer_._0/rel_attn/einsum_3/Einsum (defined at /usr/local/lib/python3.8/dist-packages/transformers/models/xlnet/modeling_tf_xlnet.py:301)\n\nFunction call stack:\npredict_function\n"
     ]
    }
   ],
   "source": [
    "# predict probabilities for test set\n",
    "test_probs = model.predict(test_data, batch_size= 1, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_probs = test_probs[\"logits\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_classes = np.argmax(test_probs, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c=0\n",
    "for i in range(test_classes.shape[0]):\n",
    "    if test_classes[i]==test_labels[i]:\n",
    "        c+=1\n",
    "print(\"Test accuracy:\")\n",
    "print(c/test_labels.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy: (tp + tn) / (p + n)\n",
    "accuracy = accuracy_score(test_labels, test_classes)\n",
    "print('Accuracy: %f' % accuracy)\n",
    "# precision tp / (tp + fp)\n",
    "precision = precision_score(test_labels, test_classes)\n",
    "print('Precision: %f' % precision)\n",
    "# recall: tp / (tp + fn)\n",
    "recall = recall_score(test_labels, test_classes)\n",
    "print('Recall: %f' % recall)\n",
    "# f1: 2 tp / (2 tp + fp + fn)\n",
    "f1 = f1_score(test_labels, test_classes)\n",
    "print('F1 score: %f' % f1)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_section.to_csv(\"train_dataset.csv\", sep='\\t')\n",
    "val_section.to_csv(\"val_dataset.csv\", sep='\\t')\n",
    "test_section.to_csv(\"test_dataset.csv\", sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save_pretrained(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
